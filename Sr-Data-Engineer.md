## Sr Data Engineer

### OVERVIEW & IMPACT:

>We are seeking a highly skilled and experienced Senior Data Engineer to join our engineering team. This role requires to identify and execute key data initiatives within the company that helps internal and external stakeholders, builds on top and extents our existing data platform, help the engineering team with the technical data needs, data warehouse design, dashboard creation, architecture and implementation of new technologies for the data platform, this role communicates among engineering and non technical team to help them how to leverage data within their team. Helps with the strategies around data governance and compliance.

### KEY RESPONSIBILITIES:

+ **Architect and Design:** Data pipelines, data warehouse, specialized datasets. 
+ **Data Services Management:** Owns our current data platform and makes decisions around improvements and technologies used within the cloud.
+ **Data Quality and Compliance:** Responsible for the data quality, data dictionary and sensitive information classification and management.
+ **Success Metrics:** Responsible for the data users success with valuable metrics, dashboards and decision making tools. 
+ **Data Solutions Delivery:** Use and Implementation of diverse data tools that provides insights to the internal and external stakeholders.

### QUALIFICATIONS & REQUIRED SKILLS:

+ **Programming:** Strong proficiency in structured query language for relational databases (SQL), Python and python libraries such as **Numpy, Pandas, PySpark. Scala** is desired but not required. **Typescript** is desired. 
+ **Code Quality:** A strong mindset around code testing and quality assurance, unit testing, integration testing, shorter feedback loops.
+ **Data Technologies:** Segment, Apache Flink, Spark, Kinesis, S3 Delta Lake, AWS Athena, DBT, Data Orchestrator (Airflow, Dagster), Data Quality Tools such as Pandera, Observability Tools such as Datadog, Sentry.
+ **AWS Expertise:** Good understanding of AWS services and configuration management.
+ **Infrastructure as Code (IaC):** Experience for managing cloud infrastructure across multiple regions. We use Terraform
+ **Automation & CI/CD:** Ability to automate repetitive tasks, reduce toil, and implement the CI/CD strategies for our Data services.
+ **Collaboration:** Strong communication and collaboration skills, with experience working in an Agile environment.
+ **Problem-Solving:** Strong analytical skills with the ability to troubleshoot complex issues in distributed systems.

### Languages & Libraries
- Numpy - Python library for large, multi-dimensional arrays and matrices
- Pandas - Python library for manipulating structured data, DataFrames and Series.
- PySpark - Python API for Apache Spark for distributed data processing
- Scala - A programming language, object-oriented and functional paradigms, for big data processing on the JVMs
- TypeScript - JavaScript with strict types
### Infrastructure as Code
- Terraform - DSL for infrastructure as code
- Pulumi - Terraform but in Python
### Data Tools
- Segment - customer data platform collects, cleans, and routes user data from various sources
- S3 Delta Lake - Storage layer on top of S3 for ACID transactions (Atomicity, Consistency, Isolation, and Durability)
- AWS Athena - Amazon's serverless query service in S3
- DBT - SQL modeling and ETL tool
- Pandera - A Python library statistical data validation and testing capabilities for pandas DataFrames
### Data Processing
- Kinesis - Amazon's service for real-time data streaming
- Spark - Distributed computing framework for fast processing of large datasets 
- Apache Flink - A distributed stream processing framework
### Data Orchestrator
- Airflow - Python-based directed acyclic graphs (DAGs) for data workflows
- Dagster - A data orchestrator for data asset management
### Observability Tools
- Datadog - A cloud-based observability platform
- Sentry - An error tracking and performance monitoring platform.
- Logfire - Python observability platform with structured logging and tracing
- ### DevOps
- CI/CD Strategy - The approach and practices to automate code integration, testing, and deployment processes.
